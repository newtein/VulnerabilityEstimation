from oval_parse import oval_parser
from nessus_parse import nessus_parser
import oval_parse as op
import sys,os
import numpy as np
import pickle
from collections import OrderedDict

try:
    loadKeys = pickle.load(open('keys.pickle','rb'))
except:
    loadKeys=set()

weights={'critical':4,'high':3,'medium':2,'low':1}
labels=['TypeA','TypeB','TypeA+B','TypeA.B']

def calculateVul(vids):
    final_mean=[]
    cveid={}
    for vid in vids:
        t_output=op.get_NVD_data(vid)
        if t_output[0]!=None and t_output[1]!=None:
            cveid[vid]=t_output
        if None not in t_output:
            final_mean.append(t_output[1])
    mean=np.mean(final_mean)

    num,denum=0,0
    for ids in cveid:
        num+=cveid[ids][1]*weights[cveid[ids][0].lower()]
        denum+=weights[cveid[ids][0].lower()]
        temp=[ids]+cveid[ids]
    try:
        weighted_mean=num/denum
    except:
        weighted_mean='None'

    print('Weighted Mean',weighted_mean,"Mean",mean)
    return mean,weighted_mean,cveid

def init_variables():
    temp=OrderedDict()
    for label in labels:
        for weight in weights:
            if label not in temp:
                temp[label]=OrderedDict()
            if weight not in temp[label]:
                temp[label][weight]=0
    return temp

def incrData(temp,label,cveids):
    for cveid in cveids:
        weight = cveids[cveid][0]
        temp[label][weight.lower()]+=1
    return temp

def vulcount(temp,label,cveids):
    if label not in temp:
        temp[label]={}
    for cveid in cveids:
        if cveid not in temp[label]:
            temp[label][cveid]=0
        temp[label][cveid]+=1
    return temp

def countwithindex(temp,label,cveids,index):
    if label not in temp:
        temp[label]={}
    for cveid in cveids:
        key=cveids[cveid][index]
        if key not in temp[label]:
            temp[label][key]=0
        temp[label][key]+=1
    return temp

def dumpPickle(name,data):
    pickle.dump(data,open('pickles/{}.pickle'.format(name),'wb'))
    return

ovalFiles=os.listdir('OVAL')
nessusFiles=os.listdir('NESSUS')
f=open('vulData.txt','w')
f2=open('nData.txt','w')
headers=['Node','Type_A_Score','Type_B_Score','Type_A+B_Score','Type_A.B_Score',\
        'Type_A_WScore','Type_B_WScore','Type_A+B_WScore','Type_A.B_WScore']
headers2=['node','N(typeA)','N(typeB)','N(typeA+B)','N(typeA.B)']

f.write(','.join(headers)+'\n')
f2.write(','.join(headers2)+'\n')
riskFrequency=init_variables()
countVul={}
countattack,countVendor,countProduct={},{},{}
for ovalFile in ovalFiles:
    for nessusFile in nessusFiles:
        key1=ovalFile.split('_')[0]
        key2=nessusFile.split('_')[0]

        if key1==key2:
            #if key1 not in loadKeys:
                loadKeys.add(key1)

                temp=[]
                nData=[]
                temp.append(key1)
                nData.append(key1)

                Omean,Oweight_mean,oval_set=oval_parser('OVAL/'+ovalFile)
                Nmean,Nweight_mean,nessus_set = nessus_parser('NESSUS/'+nessusFile)
                unionSet=set(oval_set).union(set(nessus_set))
                interSet=set(oval_set).intersection(set(nessus_set))
                
                riskFrequency=incrData(riskFrequency,'TypeA',oval_set)
                riskFrequency=incrData(riskFrequency,'TypeB',nessus_set)
                countVul=vulcount(countVul,'TypeA',oval_set)
                countVul=vulcount(countVul,'TypeB',nessus_set)
                countattack=countwithindex(countattack,'TypeA',oval_set,2)
                countattack=countwithindex(countattack,'TypeB',nessus_set,2)
                countVendor=countwithindex(countVendor,'TypeA',oval_set,3)
                countVendor=countwithindex(countVendor,'TypeB',nessus_set,3)
                countProduct=countwithindex(countProduct,'TypeA',oval_set,4)
                countProduct=countwithindex(countProduct,'TypeB',nessus_set,4)

                unionMean,unionWMean,union_set=calculateVul(unionSet)
                interMean,interWMean,inter_set=calculateVul(interSet)
                
                riskFrequency=incrData(riskFrequency,'TypeA+B',union_set)
                riskFrequency=incrData(riskFrequency,'TypeA.B',inter_set)
                countVul=vulcount(countVul,'TypeA+B',union_set)
                countVul=vulcount(countVul,'TypeA.B',inter_set)
                countattack=countwithindex(countattack,'TypeA+B',union_set,2)
                countattack=countwithindex(countattack,'TypeA.B',inter_set,2)
                countVendor=countwithindex(countVendor,'TypeA+B',union_set,3)
                countVendor=countwithindex(countVendor,'TypeA.B',inter_set,3)
                countProduct=countwithindex(countProduct,'TypeA+B',union_set,4)
                countProduct=countwithindex(countProduct,'TypeA.B',inter_set,4)

                temp.extend([Omean,Nmean,unionMean,interMean])
                temp.extend([Oweight_mean,Nweight_mean,unionWMean,interWMean])
                
                nData.extend([len(oval_set),len(nessus_set),len(unionSet),len(interSet)])
                f.write(','.join([str(i) for i in temp])+'\n')
                f2.write(','.join([str(i) for i in nData])+'\n')
                print(key1,Omean,Nmean,Oweight_mean,Nweight_mean)
               

f.close()
f2.close()
pickle.dump(loadKeys,open('keys.pickle','wb'))
dumpPickle('riskFrequency',riskFrequency)
dumpPickle('countVul',countVul)
dumpPickle('countattack',countattack)
dumpPickle('countVendor',countVendor)
dumpPickle('countProduct',countProduct)